{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_selenium.csv')\n",
    "summaries = data['Summary']\n",
    "analyses = data['Analysis']\n",
    "titles = data['Title']\n",
    "\n",
    "corpus = [f\"{title} {summary} {analysis}\" for title, summary, analysis in zip(titles, summaries, analyses)]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "preprocessed_corpus = [preprocess_text(text) for text in corpus]\n",
    "\n",
    "tokenized_corpus = [text.split() for text in preprocessed_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word Embedding Model To Obtain Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "Word2Vec_model_sg = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "Word2Vec_model_sg.save('Word2Vec_model_sg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18757609 -0.02523065  0.10822345  0.25279427  0.09404436 -0.14556998\n",
      "  0.31167802  0.56639236 -0.07748945 -0.11939991 -0.2481058  -0.37848467\n",
      " -0.0188977  -0.1670922  -0.10497189 -0.08356968 -0.0615345   0.10890697\n",
      " -0.10079912 -0.40617284 -0.00819069 -0.1524098   0.16265742 -0.03898332\n",
      " -0.06940196  0.04204768 -0.03904338 -0.06583715 -0.15557028  0.20045884\n",
      "  0.3325572   0.00232724  0.14604664 -0.25277588 -0.20083642  0.21060328\n",
      "  0.01625244 -0.34341818 -0.21040498 -0.30221328  0.05520817 -0.08441182\n",
      "  0.0313545   0.01122725  0.27458957 -0.2581353  -0.3079668  -0.02439034\n",
      " -0.22528283  0.05035021 -0.07226291 -0.00409833 -0.03894206  0.06516527\n",
      "  0.09041492 -0.08996686  0.08819439 -0.06942315  0.07562473  0.10474674\n",
      "  0.00300599 -0.16347326  0.36412808  0.02851762 -0.01989603  0.17973474\n",
      "  0.06861334  0.25913286 -0.15470749  0.06786061 -0.00504779  0.20889491\n",
      "  0.2030788  -0.25446317  0.15321966  0.13806863  0.31823     0.15149638\n",
      " -0.43128183 -0.07699223 -0.12870276 -0.00841347  0.10805228  0.12347965\n",
      "  0.12361367  0.10686838  0.18896607  0.06795093  0.2968159   0.09123122\n",
      "  0.21289487  0.4078225   0.00973898  0.17752181  0.34776276 -0.07055833\n",
      " -0.01305874 -0.35923305  0.16940497  0.01615659]\n"
     ]
    }
   ],
   "source": [
    "test_vector = Word2Vec_model_sg.wv['darkness']\n",
    "print(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('brother', 0.8718932867050171), ('wife', 0.8443353176116943), ('servant', 0.8382858633995056), ('sister', 0.8214103579521179), ('aunt', 0.8185446858406067), ('girlfriend', 0.8092584609985352), ('acquaintance', 0.802879810333252), ('grandfather', 0.8003736138343811), ('roommate', 0.7951571345329285), ('companion', 0.7915104627609253)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = Word2Vec_model_sg.wv.most_similar('friend')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar entry: the-killers George brings Max and Al their meals, but they can’t remember who ordered what. As they eat, they catch George looking at them. Al suggests that “maybe the boy meant it for a joke,” and George laughs. Max tells him not to laugh and George says alright. To Al, Max says “he thinks it’s all right,” and Al replies, “Oh, he’s a thinker.” Max and Al want to seem like they are in control of the situation and know what they are doing, but their confusion over who ordered what reveals how easy it is to fluster them (and shows them to be either a little stupid or unobservant—an inauspicious beginning for criminals). Frustrated by this confusion, they again emasculate George to put him in his place as their inferior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def sentence_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    valid_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(valid_vectors, axis=0) if valid_vectors else np.zeros(model.vector_size)\n",
    "\n",
    "user_input = \"I am feeling very sad and lonely. I don't have any friends to talk to.\"\n",
    "preprocessed_input = preprocess_text(user_input)\n",
    "input_vector = sentence_vector(preprocessed_input, Word2Vec_model_sg)\n",
    "\n",
    "corpus_vectors = [sentence_vector(entry, Word2Vec_model_sg) for entry in preprocessed_corpus]\n",
    "similarities = cosine_similarity([input_vector], corpus_vectors)\n",
    "\n",
    "most_similar_index = np.argmax(similarities)\n",
    "print(f\"Most similar entry: {corpus[most_similar_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5-Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('test_selenium.csv')\n",
    "data['Input'] = data['Summary']\n",
    "data['Output'] = data['Analysis']\n",
    "\n",
    "data[['Input', 'Output']].to_csv('fine_tuning_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5095 examples [00:00, 73840.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4126\n",
      "Validation size: 459\n",
      "Test size: 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\"train\": 'fine_tuning_data.csv'})\n",
    "\n",
    "split = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "test_dataset = split['test']\n",
    "\n",
    "split = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4126/4126 [00:03<00:00, 1372.13 examples/s]\n",
      "Map: 100%|██████████| 459/459 [00:00<00:00, 1412.30 examples/s]\n",
      "Map: 100%|██████████| 510/510 [00:00<00:00, 1408.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Check for empty inputs or outputs\n",
    "    if \"Input\" not in examples or \"Output\" not in examples:\n",
    "        raise ValueError(\"Input or output column missing in dataset.\")\n",
    "    \n",
    "    # Ensure input and output are non-empty strings\n",
    "    inputs = examples[\"Input\"]  # Replace with your dataset's input column\n",
    "    targets = examples[\"Output\"]  # Replace with your dataset's output column\n",
    "    \n",
    "    if not inputs or not targets:\n",
    "        raise ValueError(\"Empty input or output found in the dataset.\")\n",
    "\n",
    "    # Tokenize inputs and outputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Reapply preprocessing\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from torch import cuda\n",
    "print(cuda.is_available())  # Should return True if GPU is available\n",
    "\n",
    "cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")  # Replace with the appropriate metric for your task\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a list of strings\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {key: value.mid.fmeasure for key, value in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 540/3093 [46:10<3:38:18,  5.13s/it]\n",
      "  8%|▊         | 100/1290 [00:25<05:10,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1581, 'grad_norm': 0.3415832221508026, 'learning_rate': 2.7674418604651162e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 200/1290 [00:51<04:41,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1516, 'grad_norm': 0.33523938059806824, 'learning_rate': 2.5348837209302324e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 258/1290 [01:06<04:23,  3.92it/s]\n",
      " 20%|██        | 258/1290 [02:26<04:23,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1029659509658813, 'eval_rouge1': 0.22700377966625454, 'eval_rouge2': 0.038164259311995546, 'eval_rougeL': 0.1573013775566554, 'eval_rougeLsum': 0.15728417719725557, 'eval_runtime': 79.6243, 'eval_samples_per_second': 5.765, 'eval_steps_per_second': 0.728, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 300/1290 [02:38<04:14,  3.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1731, 'grad_norm': 0.4614662230014801, 'learning_rate': 2.302325581395349e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 400/1290 [03:04<03:48,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1377, 'grad_norm': 0.3278246521949768, 'learning_rate': 2.069767441860465e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 500/1290 [03:30<03:27,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1569, 'grad_norm': 0.3780752420425415, 'learning_rate': 1.8372093023255815e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 516/1290 [03:34<03:13,  4.00it/s]\n",
      " 40%|████      | 516/1290 [04:54<03:13,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1011240482330322, 'eval_rouge1': 0.2275511181561969, 'eval_rouge2': 0.03803725032615746, 'eval_rougeL': 0.15706523098023903, 'eval_rougeLsum': 0.15708350142359637, 'eval_runtime': 79.5357, 'eval_samples_per_second': 5.771, 'eval_steps_per_second': 0.729, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 600/1290 [05:17<03:01,  3.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1412, 'grad_norm': 0.47076189517974854, 'learning_rate': 1.6046511627906977e-05, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 700/1290 [05:43<02:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1677, 'grad_norm': 0.3033689558506012, 'learning_rate': 1.3720930232558139e-05, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 774/1290 [06:02<02:08,  4.01it/s]\n",
      " 60%|██████    | 774/1290 [07:22<02:08,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0996617078781128, 'eval_rouge1': 0.2258617359052731, 'eval_rouge2': 0.03663470168663069, 'eval_rougeL': 0.1577939218582619, 'eval_rougeLsum': 0.15774778563332564, 'eval_runtime': 79.2244, 'eval_samples_per_second': 5.794, 'eval_steps_per_second': 0.732, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 800/1290 [07:30<02:08,  3.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1374, 'grad_norm': 0.3430788815021515, 'learning_rate': 1.1395348837209304e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 900/1290 [07:56<01:42,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1338, 'grad_norm': 0.3221055269241333, 'learning_rate': 9.069767441860465e-06, 'epoch': 3.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1000/1290 [08:22<01:14,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1626, 'grad_norm': 0.3305850327014923, 'learning_rate': 6.744186046511628e-06, 'epoch': 3.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1032/1290 [08:30<01:05,  3.93it/s]\n",
      " 80%|████████  | 1032/1290 [09:50<01:05,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0990241765975952, 'eval_rouge1': 0.22739687748533494, 'eval_rouge2': 0.037879815796081004, 'eval_rougeL': 0.15749871318715244, 'eval_rougeLsum': 0.1575788237634107, 'eval_runtime': 79.9954, 'eval_samples_per_second': 5.738, 'eval_steps_per_second': 0.725, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1100/1290 [10:09<00:48,  3.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1513, 'grad_norm': 0.3287399411201477, 'learning_rate': 4.418604651162791e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1200/1290 [10:35<00:23,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1353, 'grad_norm': 0.258544921875, 'learning_rate': 2.0930232558139536e-06, 'epoch': 4.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1290/1290 [10:59<00:00,  4.03it/s]\n",
      "100%|██████████| 1290/1290 [12:12<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0988032817840576, 'eval_rouge1': 0.22696615737281944, 'eval_rouge2': 0.03729638835198566, 'eval_rougeL': 0.15664572417852665, 'eval_rougeLsum': 0.15668347390048837, 'eval_runtime': 73.338, 'eval_samples_per_second': 6.259, 'eval_steps_per_second': 0.791, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1290/1290 [12:14<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 734.1109, 'train_samples_per_second': 28.102, 'train_steps_per_second': 1.757, 'train_loss': 1.1504131110139595, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_t5_tokenizer\\\\tokenizer_config.json',\n",
       " 'fine_tuned_t5_tokenizer\\\\special_tokens_map.json',\n",
       " 'fine_tuned_t5_tokenizer\\\\spiece.model',\n",
       " 'fine_tuned_t5_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Clear GPU cache and set memory configuration\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./fine_tuned_t5\",\n",
    "    evaluation_strategy=\"epoch\",         # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",               # Save model after each epoch\n",
    "    learning_rate=3e-5,                  # Lower learning rate for better fine-tuning\n",
    "    per_device_train_batch_size=8,       # Increase batch size if memory allows\n",
    "    per_device_eval_batch_size=8,        # Match eval batch size to train batch size\n",
    "    gradient_accumulation_steps=2,       # Adjust accumulation to simulate a larger batch size\n",
    "    num_train_epochs=5,                  # Increase epochs to ensure better learning\n",
    "    weight_decay=0.01,                   # Retain weight decay for regularization\n",
    "    save_total_limit=3,                  # Save more models to track progress\n",
    "    logging_steps=100,                   # Log more frequently for monitoring\n",
    "    fp16=True,                           # Enable mixed precision for faster training\n",
    "    predict_with_generate=True,          # Enable text generation during evaluation\n",
    "    load_best_model_at_end=True,         # Load the best model based on `metric_for_best_model`\n",
    "    metric_for_best_model=\"eval_loss\",   # Monitor evaluation loss for the best model\n",
    "    greater_is_better=False,             # Ensure lower eval loss is considered better\n",
    "    generation_max_length=50,            # Limit generated sequences for evaluation\n",
    "    generation_num_beams=5               # Use beam search to improve text quality\n",
    ")\n",
    "\n",
    "\n",
    "# Use Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics  # Custom evaluation metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('fine_tuned_t5')\n",
    "tokenizer.save_pretrained('fine_tuned_t5_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [01:17<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 1.0988032817840576, 'eval_rouge1': 0.22696615737281944, 'eval_rouge2': 0.03729638835198566, 'eval_rougeL': 0.15664572417852665, 'eval_rougeLsum': 0.15668347390048837, 'eval_runtime': 78.7555, 'eval_samples_per_second': 5.828, 'eval_steps_per_second': 0.736, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 64/64 [01:26<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.33490390490526056, recall=0.17585545015694035, fmeasure=0.22227520474270832), mid=Score(precision=0.3456705877825293, recall=0.18182642521811035, fmeasure=0.22838538736343567), high=Score(precision=0.35691200460215605, recall=0.18789847350357655, fmeasure=0.2343835681186756)), 'rouge2': AggregateScore(low=Score(precision=0.05973564524231359, recall=0.030422373890142934, fmeasure=0.03864302808661215), mid=Score(precision=0.06500702428665237, recall=0.03304585805641032, fmeasure=0.04170054544086488), high=Score(precision=0.07117429085479514, recall=0.035979287572104605, fmeasure=0.04520067528191159)), 'rougeL': AggregateScore(low=Score(precision=0.2347150391897406, recall=0.12352538524628558, fmeasure=0.15561207945120936), mid=Score(precision=0.2422539886059607, recall=0.12787330407500191, fmeasure=0.1602583425936732), high=Score(precision=0.25028880451836044, recall=0.13252656077306516, fmeasure=0.16481078152687148)), 'rougeLsum': AggregateScore(low=Score(precision=0.23381340555275593, recall=0.12347441075498884, fmeasure=0.15564998190345206), mid=Score(precision=0.2418899579619468, recall=0.12794046671790393, fmeasure=0.16005127113485895), high=Score(precision=0.24974483665785058, recall=0.13205905506062238, fmeasure=0.1642758181669732))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(predictions.label_ids, skip_special_tokens=True)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "print(\"ROUGE Scores:\", rouge_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: {'bleu': 0.007736160222513284, 'precisions': [0.2797606767072416, 0.03862875062361913, 0.009244878337401079, 0.0024594573822150486], 'brevity_penalty': 0.34746894643613147, 'length_ratio': 0.4861259695105643, 'translation_length': 14541, 'reference_length': 29912}\n"
     ]
    }
   ],
   "source": [
    "# Load BLEU metric\n",
    "bleu = load_metric(\"bleu\")\n",
    "\n",
    "# BLEU requires tokenized predictions and references\n",
    "tokenized_preds = [pred.split() for pred in decoded_preds]\n",
    "tokenized_labels = [[ref.split()] for ref in decoded_labels]  # BLEU expects a list of references for each prediction\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_result = bleu.compute(predictions=tokenized_preds, references=tokenized_labels)\n",
    "print(\"BLEU Score:\", bleu_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract ROUGE scores (F-measure)\n",
    "rouge_scores = {\n",
    "    \"ROUGE-1\": rouge_result[\"rouge1\"].mid.fmeasure,\n",
    "    \"ROUGE-2\": rouge_result[\"rouge2\"].mid.fmeasure,\n",
    "    \"ROUGE-L\": rouge_result[\"rougeL\"].mid.fmeasure,\n",
    "}\n",
    "\n",
    "# Plot ROUGE scores\n",
    "plt.bar(rouge_scores.keys(), rouge_scores.values())\n",
    "plt.title(\"ROUGE Scores\")\n",
    "plt.ylabel(\"F-Measure\")\n",
    "plt.xlabel(\"ROUGE Metric\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot BLEU score\n",
    "plt.bar([\"BLEU\"], [bleu_result[\"bleu\"]])\n",
    "plt.title(\"BLEU Score\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: The nihilistic reflections of Henry’s life in Paris begin to emerge. Boris seems to be allowing him to stay with him for free, though he employs various excuses to avoid his repeated requests for breakfast. He has spent his years in Paris as an aspiring writer, but he is not relinquishing his sense of himself as an “artist.”\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, though not relinquishing his sense of himself as an “artist” in a vaguer sense.\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(\"cuda\")  # Move to GPU if available\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,         # Allow for longer outputs if needed\n",
    "    num_beams=10,           # Increase beams for more refined results\n",
    "    repetition_penalty=2.0, # Penalize repetitive outputs\n",
    "    length_penalty=2.0,     # Encourage longer outputs\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('test_selenium.csv')\n",
    "data['Input'] = data['Summary']\n",
    "data['Output'] = data['Analysis']\n",
    "\n",
    "data[['Input', 'Output']].to_csv('fine_tuning_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5095 examples [00:00, 66169.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4126\n",
      "Validation size: 459\n",
      "Test size: 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\"train\": 'fine_tuning_data.csv'})\n",
    "\n",
    "split = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "test_dataset = split['test']\n",
    "\n",
    "split = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/4126 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4126/4126 [00:02<00:00, 1394.86 examples/s]\n",
      "Map: 100%|██████████| 459/459 [00:00<00:00, 1342.12 examples/s]\n",
      "Map: 100%|██████████| 510/510 [00:00<00:00, 1401.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Check for empty inputs or outputs\n",
    "    if \"Input\" not in examples or \"Output\" not in examples:\n",
    "        raise ValueError(\"Input or output column missing in dataset.\")\n",
    "    \n",
    "    # Ensure input and output are non-empty strings\n",
    "    inputs = examples[\"Input\"]  # Replace with your dataset's input column\n",
    "    targets = examples[\"Output\"]  # Replace with your dataset's output column\n",
    "    \n",
    "    if not inputs or not targets:\n",
    "        raise ValueError(\"Empty input or output found in the dataset.\")\n",
    "\n",
    "    # Tokenize inputs and outputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Reapply preprocessing\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from torch import cuda\n",
    "print(cuda.is_available())  # Should return True if GPU is available\n",
    "\n",
    "cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")  # Replace with the appropriate metric for your task\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a list of strings\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {key: value.mid.fmeasure for key, value in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1290 [18:34<3:43:22, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0036, 'grad_norm': 0.5352179408073425, 'learning_rate': 2.772093023255814e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 200/1290 [37:21<3:24:35, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.098, 'grad_norm': 0.4563276767730713, 'learning_rate': 2.5395348837209305e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 258/1290 [48:12<3:05:35, 10.79s/it]\n",
      " 20%|██        | 258/1290 [1:03:09<3:05:35, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0034279823303223, 'eval_rouge1': 0.21330438522053924, 'eval_rouge2': 0.03399455421505811, 'eval_rougeL': 0.14934999283020733, 'eval_rougeLsum': 0.14941194965090807, 'eval_runtime': 896.933, 'eval_samples_per_second': 0.512, 'eval_steps_per_second': 0.065, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 300/1290 [1:11:07<3:05:48, 11.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.085, 'grad_norm': 0.361490935087204, 'learning_rate': 2.3069767441860467e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 400/1290 [1:29:53<2:47:01, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.046, 'grad_norm': 1.320412039756775, 'learning_rate': 2.0767441860465117e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 500/1290 [1:48:39<2:28:21, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0549, 'grad_norm': 0.3809065520763397, 'learning_rate': 1.8465116279069767e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 516/1290 [1:51:37<2:19:15, 10.80s/it]\n",
      " 40%|████      | 516/1290 [2:06:34<2:19:15, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9842826724052429, 'eval_rouge1': 0.2226126314296869, 'eval_rouge2': 0.035853406862112594, 'eval_rougeL': 0.15578856103838382, 'eval_rougeLsum': 0.15587749376865712, 'eval_runtime': 896.8964, 'eval_samples_per_second': 0.512, 'eval_steps_per_second': 0.065, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 600/1290 [2:23:12<2:09:34, 11.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0368, 'grad_norm': 0.3600267171859741, 'learning_rate': 1.618604651162791e-05, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 700/1290 [2:41:58<1:51:14, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0489, 'grad_norm': 0.3259245455265045, 'learning_rate': 1.3883720930232559e-05, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 774/1290 [2:55:50<1:32:57, 10.81s/it]\n",
      " 60%|██████    | 774/1290 [3:10:49<1:32:57, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9773697853088379, 'eval_rouge1': 0.22660362339030554, 'eval_rouge2': 0.03679759924880288, 'eval_rougeL': 0.157671887064616, 'eval_rougeLsum': 0.15779711569025412, 'eval_runtime': 898.5777, 'eval_samples_per_second': 0.511, 'eval_steps_per_second': 0.065, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 800/1290 [3:17:04<1:32:21, 11.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0158, 'grad_norm': 0.32497265934944153, 'learning_rate': 1.155813953488372e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 900/1290 [3:35:50<1:13:12, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.012, 'grad_norm': 0.47201111912727356, 'learning_rate': 9.255813953488373e-06, 'epoch': 3.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1000/1290 [3:54:36<54:26, 11.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0381, 'grad_norm': 0.35459429025650024, 'learning_rate': 6.953488372093023e-06, 'epoch': 3.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1032/1290 [4:00:34<46:24, 10.79s/it]\n",
      " 80%|████████  | 1032/1290 [4:15:32<46:24, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9738273620605469, 'eval_rouge1': 0.22760707661331753, 'eval_rouge2': 0.03915433961168167, 'eval_rougeL': 0.15696193694760074, 'eval_rougeLsum': 0.15702878608010318, 'eval_runtime': 897.3999, 'eval_samples_per_second': 0.511, 'eval_steps_per_second': 0.065, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1100/1290 [4:28:39<35:39, 11.26s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0269, 'grad_norm': 0.4196864664554596, 'learning_rate': 4.651162790697674e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1200/1290 [4:47:25<16:53, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0058, 'grad_norm': 0.351889044046402, 'learning_rate': 2.325581395348837e-06, 'epoch': 4.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1290/1290 [5:04:18<00:00, 10.81s/it]\n",
      "100%|██████████| 1290/1290 [5:19:17<00:00, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9726053476333618, 'eval_rouge1': 0.2269705826240465, 'eval_rouge2': 0.03897308848209827, 'eval_rougeL': 0.15687984192300186, 'eval_rougeLsum': 0.15699735267020376, 'eval_runtime': 898.9952, 'eval_samples_per_second': 0.511, 'eval_steps_per_second': 0.065, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1290/1290 [5:19:25<00:00, 14.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 19165.2081, 'train_samples_per_second': 1.076, 'train_steps_per_second': 0.067, 'train_loss': 1.192525949404221, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_t5_base_tokenizer\\\\tokenizer_config.json',\n",
       " 'fine_tuned_t5_base_tokenizer\\\\special_tokens_map.json',\n",
       " 'fine_tuned_t5_base_tokenizer\\\\spiece.model',\n",
       " 'fine_tuned_t5_base_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Clear GPU cache and set memory configuration\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./fine_tuned_t5_base\",\n",
    "    evaluation_strategy=\"epoch\",         # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",               # Save model after each epoch\n",
    "    learning_rate=3e-5,                  # Lower learning rate for better fine-tuning\n",
    "    per_device_train_batch_size=8,       # Increase batch size if memory allows\n",
    "    per_device_eval_batch_size=8,        # Match eval batch size to train batch size\n",
    "    gradient_accumulation_steps=2,       # Adjust accumulation to simulate a larger batch size\n",
    "    num_train_epochs=5,                  # Increase epochs to ensure better learning\n",
    "    weight_decay=0.01,                   # Retain weight decay for regularization\n",
    "    save_total_limit=3,                  # Save more models to track progress\n",
    "    logging_steps=100,                   # Log more frequently for monitoring\n",
    "    fp16=True,                           # Enable mixed precision for faster training\n",
    "    predict_with_generate=True,          # Enable text generation during evaluation\n",
    "    load_best_model_at_end=True,         # Load the best model based on `metric_for_best_model`\n",
    "    metric_for_best_model=\"eval_loss\",   # Monitor evaluation loss for the best model\n",
    "    greater_is_better=False,             # Ensure lower eval loss is considered better\n",
    "    generation_max_length=50,            # Limit generated sequences for evaluation\n",
    "    generation_num_beams=5               # Use beam search to improve text quality\n",
    ")\n",
    "\n",
    "\n",
    "# Use Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics  # Custom evaluation metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('fine_tuned_t5_base')\n",
    "tokenizer.save_pretrained('fine_tuned_t5_base_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5_base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_base_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [14:44<00:00, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.9726053476333618, 'eval_rouge1': 0.2269705826240465, 'eval_rouge2': 0.03897308848209827, 'eval_rougeL': 0.15687984192300186, 'eval_rougeLsum': 0.15699735267020376, 'eval_runtime': 900.2685, 'eval_samples_per_second': 0.51, 'eval_steps_per_second': 0.064, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 64/64 [16:16<00:00, 15.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.3446536811053453, recall=0.1849706203815666, fmeasure=0.23182983814689817), mid=Score(precision=0.35525199348421155, recall=0.19050600872033885, fmeasure=0.23733365134321482), high=Score(precision=0.36714105509458533, recall=0.19620984050528292, fmeasure=0.24323347703904735)), 'rouge2': AggregateScore(low=Score(precision=0.05992040881822796, recall=0.030206934758016012, fmeasure=0.038628937876394126), mid=Score(precision=0.06487041168480118, recall=0.03299704250008457, fmeasure=0.04174958708253598), high=Score(precision=0.07062634605208207, recall=0.036140482961159834, fmeasure=0.04543944810829001)), 'rougeL': AggregateScore(low=Score(precision=0.23554908439521832, recall=0.12707142020187762, fmeasure=0.15885798653413744), mid=Score(precision=0.24241193027085614, recall=0.1315505995484887, fmeasure=0.16285369759996485), high=Score(precision=0.24912292288387083, recall=0.13639093086056395, fmeasure=0.16727259449856244)), 'rougeLsum': AggregateScore(low=Score(precision=0.23561289716058628, recall=0.12708465684166265, fmeasure=0.15875584977611057), mid=Score(precision=0.24219233490078537, recall=0.13172359946664736, fmeasure=0.16298446386274176), high=Score(precision=0.2489667896823867, recall=0.13627314115785608, fmeasure=0.1671213778145019))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(predictions.label_ids, skip_special_tokens=True)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "print(\"ROUGE Scores:\", rouge_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: {'bleu': 0.007072247200609285, 'precisions': [0.28503239004432324, 0.037089367714588484, 0.008647856357640161, 0.0017510468214693568], 'brevity_penalty': 0.35356556818871576, 'length_ratio': 0.49027146295801016, 'translation_length': 14665, 'reference_length': 29912}\n"
     ]
    }
   ],
   "source": [
    "# Load BLEU metric\n",
    "bleu = load_metric(\"bleu\")\n",
    "\n",
    "# BLEU requires tokenized predictions and references\n",
    "tokenized_preds = [pred.split() for pred in decoded_preds]\n",
    "tokenized_labels = [[ref.split()] for ref in decoded_labels]  # BLEU expects a list of references for each prediction\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_result = bleu.compute(predictions=tokenized_preds, references=tokenized_labels)\n",
    "print(\"BLEU Score:\", bleu_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract ROUGE scores (F-measure)\n",
    "rouge_scores = {\n",
    "    \"ROUGE-1\": rouge_result[\"rouge1\"].mid.fmeasure,\n",
    "    \"ROUGE-2\": rouge_result[\"rouge2\"].mid.fmeasure,\n",
    "    \"ROUGE-L\": rouge_result[\"rougeL\"].mid.fmeasure,\n",
    "}\n",
    "\n",
    "# Plot ROUGE scores\n",
    "plt.bar(rouge_scores.keys(), rouge_scores.values())\n",
    "plt.title(\"ROUGE Scores\")\n",
    "plt.ylabel(\"F-Measure\")\n",
    "plt.xlabel(\"ROUGE Metric\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot BLEU score\n",
    "plt.bar([\"BLEU\"], [bleu_result[\"bleu\"]])\n",
    "plt.title(\"BLEU Score\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he doesn’t relinquish his sense of himself as an “artist.”\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, though not relinquishing his sense of himself as an “artist” in a vaguer sense.\"\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(\"cuda\")  # Move to GPU if available\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,         # Allow for longer outputs if needed\n",
    "    num_beams=10,           # Increase beams for more refined results\n",
    "    repetition_penalty=2.0, # Penalize repetitive outputs\n",
    "    length_penalty=2.0,     # Encourage longer outputs\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (2.2.2+cu118)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (4.40.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (1.26.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (3.8.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from matplotlib->bert-score) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from requests->bert-score) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert-score) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 10.2/61.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.1/61.1 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_tokenizer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4126\n",
      "Validation size: 459\n",
      "Test size: 510\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\"train\": 'fine_tuning_data.csv'})\n",
    "\n",
    "split = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "test_dataset = split['test']\n",
    "\n",
    "split = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  1 / 510\n",
      "Done:  2 / 510\n",
      "Done:  3 / 510\n",
      "Done:  4 / 510\n",
      "Done:  5 / 510\n",
      "Done:  6 / 510\n",
      "Done:  7 / 510\n",
      "Done:  8 / 510\n",
      "Done:  9 / 510\n",
      "Done:  10 / 510\n",
      "Done:  11 / 510\n",
      "Done:  12 / 510\n",
      "Done:  13 / 510\n",
      "Done:  14 / 510\n",
      "Done:  15 / 510\n",
      "Done:  16 / 510\n",
      "Done:  17 / 510\n",
      "Done:  18 / 510\n",
      "Done:  19 / 510\n",
      "Done:  20 / 510\n",
      "Done:  21 / 510\n",
      "Done:  22 / 510\n",
      "Done:  23 / 510\n",
      "Done:  24 / 510\n",
      "Done:  25 / 510\n",
      "Done:  26 / 510\n",
      "Done:  27 / 510\n",
      "Done:  28 / 510\n",
      "Done:  29 / 510\n",
      "Done:  30 / 510\n",
      "Done:  31 / 510\n",
      "Done:  32 / 510\n",
      "Done:  33 / 510\n",
      "Done:  34 / 510\n",
      "Done:  35 / 510\n",
      "Done:  36 / 510\n",
      "Done:  37 / 510\n",
      "Done:  38 / 510\n",
      "Done:  39 / 510\n",
      "Done:  40 / 510\n",
      "Done:  41 / 510\n",
      "Done:  42 / 510\n",
      "Done:  43 / 510\n",
      "Done:  44 / 510\n",
      "Done:  45 / 510\n",
      "Done:  46 / 510\n",
      "Done:  47 / 510\n",
      "Done:  48 / 510\n",
      "Done:  49 / 510\n",
      "Done:  50 / 510\n",
      "Done:  51 / 510\n",
      "Done:  52 / 510\n",
      "Done:  53 / 510\n",
      "Done:  54 / 510\n",
      "Done:  55 / 510\n",
      "Done:  56 / 510\n",
      "Done:  57 / 510\n",
      "Done:  58 / 510\n",
      "Done:  59 / 510\n",
      "Done:  60 / 510\n",
      "Done:  61 / 510\n",
      "Done:  62 / 510\n",
      "Done:  63 / 510\n",
      "Done:  64 / 510\n",
      "Done:  65 / 510\n",
      "Done:  66 / 510\n",
      "Done:  67 / 510\n",
      "Done:  68 / 510\n",
      "Done:  69 / 510\n",
      "Done:  70 / 510\n",
      "Done:  71 / 510\n",
      "Done:  72 / 510\n",
      "Done:  73 / 510\n",
      "Done:  74 / 510\n",
      "Done:  75 / 510\n",
      "Done:  76 / 510\n",
      "Done:  77 / 510\n",
      "Done:  78 / 510\n",
      "Done:  79 / 510\n",
      "Done:  80 / 510\n",
      "Done:  81 / 510\n",
      "Done:  82 / 510\n",
      "Done:  83 / 510\n",
      "Done:  84 / 510\n",
      "Done:  85 / 510\n",
      "Done:  86 / 510\n",
      "Done:  87 / 510\n",
      "Done:  88 / 510\n",
      "Done:  89 / 510\n",
      "Done:  90 / 510\n",
      "Done:  91 / 510\n",
      "Done:  92 / 510\n",
      "Done:  93 / 510\n",
      "Done:  94 / 510\n",
      "Done:  95 / 510\n",
      "Done:  96 / 510\n",
      "Done:  97 / 510\n",
      "Done:  98 / 510\n",
      "Done:  99 / 510\n",
      "Done:  100 / 510\n",
      "Done:  101 / 510\n",
      "Done:  102 / 510\n",
      "Done:  103 / 510\n",
      "Done:  104 / 510\n",
      "Done:  105 / 510\n",
      "Done:  106 / 510\n",
      "Done:  107 / 510\n",
      "Done:  108 / 510\n",
      "Done:  109 / 510\n",
      "Done:  110 / 510\n",
      "Done:  111 / 510\n",
      "Done:  112 / 510\n",
      "Done:  113 / 510\n",
      "Done:  114 / 510\n",
      "Done:  115 / 510\n",
      "Done:  116 / 510\n",
      "Done:  117 / 510\n",
      "Done:  118 / 510\n",
      "Done:  119 / 510\n",
      "Done:  120 / 510\n",
      "Done:  121 / 510\n",
      "Done:  122 / 510\n",
      "Done:  123 / 510\n",
      "Done:  124 / 510\n",
      "Done:  125 / 510\n",
      "Done:  126 / 510\n",
      "Done:  127 / 510\n",
      "Done:  128 / 510\n",
      "Done:  129 / 510\n",
      "Done:  130 / 510\n",
      "Done:  131 / 510\n",
      "Done:  132 / 510\n",
      "Done:  133 / 510\n",
      "Done:  134 / 510\n",
      "Done:  135 / 510\n",
      "Done:  136 / 510\n",
      "Done:  137 / 510\n",
      "Done:  138 / 510\n",
      "Done:  139 / 510\n",
      "Done:  140 / 510\n",
      "Done:  141 / 510\n",
      "Done:  142 / 510\n",
      "Done:  143 / 510\n",
      "Done:  144 / 510\n",
      "Done:  145 / 510\n",
      "Done:  146 / 510\n",
      "Done:  147 / 510\n",
      "Done:  148 / 510\n",
      "Done:  149 / 510\n",
      "Done:  150 / 510\n",
      "Done:  151 / 510\n",
      "Done:  152 / 510\n",
      "Done:  153 / 510\n",
      "Done:  154 / 510\n",
      "Done:  155 / 510\n",
      "Done:  156 / 510\n",
      "Done:  157 / 510\n",
      "Done:  158 / 510\n",
      "Done:  159 / 510\n",
      "Done:  160 / 510\n",
      "Done:  161 / 510\n",
      "Done:  162 / 510\n",
      "Done:  163 / 510\n",
      "Done:  164 / 510\n",
      "Done:  165 / 510\n",
      "Done:  166 / 510\n",
      "Done:  167 / 510\n",
      "Done:  168 / 510\n",
      "Done:  169 / 510\n",
      "Done:  170 / 510\n",
      "Done:  171 / 510\n",
      "Done:  172 / 510\n",
      "Done:  173 / 510\n",
      "Done:  174 / 510\n",
      "Done:  175 / 510\n",
      "Done:  176 / 510\n",
      "Done:  177 / 510\n",
      "Done:  178 / 510\n",
      "Done:  179 / 510\n",
      "Done:  180 / 510\n",
      "Done:  181 / 510\n",
      "Done:  182 / 510\n",
      "Done:  183 / 510\n",
      "Done:  184 / 510\n",
      "Done:  185 / 510\n",
      "Done:  186 / 510\n",
      "Done:  187 / 510\n",
      "Done:  188 / 510\n",
      "Done:  189 / 510\n",
      "Done:  190 / 510\n",
      "Done:  191 / 510\n",
      "Done:  192 / 510\n",
      "Done:  193 / 510\n",
      "Done:  194 / 510\n",
      "Done:  195 / 510\n",
      "Done:  196 / 510\n",
      "Done:  197 / 510\n",
      "Done:  198 / 510\n",
      "Done:  199 / 510\n",
      "Done:  200 / 510\n",
      "Done:  201 / 510\n",
      "Done:  202 / 510\n",
      "Done:  203 / 510\n",
      "Done:  204 / 510\n",
      "Done:  205 / 510\n",
      "Done:  206 / 510\n",
      "Done:  207 / 510\n",
      "Done:  208 / 510\n",
      "Done:  209 / 510\n",
      "Done:  210 / 510\n",
      "Done:  211 / 510\n",
      "Done:  212 / 510\n",
      "Done:  213 / 510\n",
      "Done:  214 / 510\n",
      "Done:  215 / 510\n",
      "Done:  216 / 510\n",
      "Done:  217 / 510\n",
      "Done:  218 / 510\n",
      "Done:  219 / 510\n",
      "Done:  220 / 510\n",
      "Done:  221 / 510\n",
      "Done:  222 / 510\n",
      "Done:  223 / 510\n",
      "Done:  224 / 510\n",
      "Done:  225 / 510\n",
      "Done:  226 / 510\n",
      "Done:  227 / 510\n",
      "Done:  228 / 510\n",
      "Done:  229 / 510\n",
      "Done:  230 / 510\n",
      "Done:  231 / 510\n",
      "Done:  232 / 510\n",
      "Done:  233 / 510\n",
      "Done:  234 / 510\n",
      "Done:  235 / 510\n",
      "Done:  236 / 510\n",
      "Done:  237 / 510\n",
      "Done:  238 / 510\n",
      "Done:  239 / 510\n",
      "Done:  240 / 510\n",
      "Done:  241 / 510\n",
      "Done:  242 / 510\n",
      "Done:  243 / 510\n",
      "Done:  244 / 510\n",
      "Done:  245 / 510\n",
      "Done:  246 / 510\n",
      "Done:  247 / 510\n",
      "Done:  248 / 510\n",
      "Done:  249 / 510\n",
      "Done:  250 / 510\n",
      "Done:  251 / 510\n",
      "Done:  252 / 510\n",
      "Done:  253 / 510\n",
      "Done:  254 / 510\n",
      "Done:  255 / 510\n",
      "Done:  256 / 510\n",
      "Done:  257 / 510\n",
      "Done:  258 / 510\n",
      "Done:  259 / 510\n",
      "Done:  260 / 510\n",
      "Done:  261 / 510\n",
      "Done:  262 / 510\n",
      "Done:  263 / 510\n",
      "Done:  264 / 510\n",
      "Done:  265 / 510\n",
      "Done:  266 / 510\n",
      "Done:  267 / 510\n",
      "Done:  268 / 510\n",
      "Done:  269 / 510\n",
      "Done:  270 / 510\n",
      "Done:  271 / 510\n",
      "Done:  272 / 510\n",
      "Done:  273 / 510\n",
      "Done:  274 / 510\n",
      "Done:  275 / 510\n",
      "Done:  276 / 510\n",
      "Done:  277 / 510\n",
      "Done:  278 / 510\n",
      "Done:  279 / 510\n",
      "Done:  280 / 510\n",
      "Done:  281 / 510\n",
      "Done:  282 / 510\n",
      "Done:  283 / 510\n",
      "Done:  284 / 510\n",
      "Done:  285 / 510\n",
      "Done:  286 / 510\n",
      "Done:  287 / 510\n",
      "Done:  288 / 510\n",
      "Done:  289 / 510\n",
      "Done:  290 / 510\n",
      "Done:  291 / 510\n",
      "Done:  292 / 510\n",
      "Done:  293 / 510\n",
      "Done:  294 / 510\n",
      "Done:  295 / 510\n",
      "Done:  296 / 510\n",
      "Done:  297 / 510\n",
      "Done:  298 / 510\n",
      "Done:  299 / 510\n",
      "Done:  300 / 510\n",
      "Done:  301 / 510\n",
      "Done:  302 / 510\n",
      "Done:  303 / 510\n",
      "Done:  304 / 510\n",
      "Done:  305 / 510\n",
      "Done:  306 / 510\n",
      "Done:  307 / 510\n",
      "Done:  308 / 510\n",
      "Done:  309 / 510\n",
      "Done:  310 / 510\n",
      "Done:  311 / 510\n",
      "Done:  312 / 510\n",
      "Done:  313 / 510\n",
      "Done:  314 / 510\n",
      "Done:  315 / 510\n",
      "Done:  316 / 510\n",
      "Done:  317 / 510\n",
      "Done:  318 / 510\n",
      "Done:  319 / 510\n",
      "Done:  320 / 510\n",
      "Done:  321 / 510\n",
      "Done:  322 / 510\n",
      "Done:  323 / 510\n",
      "Done:  324 / 510\n",
      "Done:  325 / 510\n",
      "Done:  326 / 510\n",
      "Done:  327 / 510\n",
      "Done:  328 / 510\n",
      "Done:  329 / 510\n",
      "Done:  330 / 510\n",
      "Done:  331 / 510\n",
      "Done:  332 / 510\n",
      "Done:  333 / 510\n",
      "Done:  334 / 510\n",
      "Done:  335 / 510\n",
      "Done:  336 / 510\n",
      "Done:  337 / 510\n",
      "Done:  338 / 510\n",
      "Done:  339 / 510\n",
      "Done:  340 / 510\n",
      "Done:  341 / 510\n",
      "Done:  342 / 510\n",
      "Done:  343 / 510\n",
      "Done:  344 / 510\n",
      "Done:  345 / 510\n",
      "Done:  346 / 510\n",
      "Done:  347 / 510\n",
      "Done:  348 / 510\n",
      "Done:  349 / 510\n",
      "Done:  350 / 510\n",
      "Done:  351 / 510\n",
      "Done:  352 / 510\n",
      "Done:  353 / 510\n",
      "Done:  354 / 510\n",
      "Done:  355 / 510\n",
      "Done:  356 / 510\n",
      "Done:  357 / 510\n",
      "Done:  358 / 510\n",
      "Done:  359 / 510\n",
      "Done:  360 / 510\n",
      "Done:  361 / 510\n",
      "Done:  362 / 510\n",
      "Done:  363 / 510\n",
      "Done:  364 / 510\n",
      "Done:  365 / 510\n",
      "Done:  366 / 510\n",
      "Done:  367 / 510\n",
      "Done:  368 / 510\n",
      "Done:  369 / 510\n",
      "Done:  370 / 510\n",
      "Done:  371 / 510\n",
      "Done:  372 / 510\n",
      "Done:  373 / 510\n",
      "Done:  374 / 510\n",
      "Done:  375 / 510\n",
      "Done:  376 / 510\n",
      "Done:  377 / 510\n",
      "Done:  378 / 510\n",
      "Done:  379 / 510\n",
      "Done:  380 / 510\n",
      "Done:  381 / 510\n",
      "Done:  382 / 510\n",
      "Done:  383 / 510\n",
      "Done:  384 / 510\n",
      "Done:  385 / 510\n",
      "Done:  386 / 510\n",
      "Done:  387 / 510\n",
      "Done:  388 / 510\n",
      "Done:  389 / 510\n",
      "Done:  390 / 510\n",
      "Done:  391 / 510\n",
      "Done:  392 / 510\n",
      "Done:  393 / 510\n",
      "Done:  394 / 510\n",
      "Done:  395 / 510\n",
      "Done:  396 / 510\n",
      "Done:  397 / 510\n",
      "Done:  398 / 510\n",
      "Done:  399 / 510\n",
      "Done:  400 / 510\n",
      "Done:  401 / 510\n",
      "Done:  402 / 510\n",
      "Done:  403 / 510\n",
      "Done:  404 / 510\n",
      "Done:  405 / 510\n",
      "Done:  406 / 510\n",
      "Done:  407 / 510\n",
      "Done:  408 / 510\n",
      "Done:  409 / 510\n",
      "Done:  410 / 510\n",
      "Done:  411 / 510\n",
      "Done:  412 / 510\n",
      "Done:  413 / 510\n",
      "Done:  414 / 510\n",
      "Done:  415 / 510\n",
      "Done:  416 / 510\n",
      "Done:  417 / 510\n",
      "Done:  418 / 510\n",
      "Done:  419 / 510\n",
      "Done:  420 / 510\n",
      "Done:  421 / 510\n",
      "Done:  422 / 510\n",
      "Done:  423 / 510\n",
      "Done:  424 / 510\n",
      "Done:  425 / 510\n",
      "Done:  426 / 510\n",
      "Done:  427 / 510\n",
      "Done:  428 / 510\n",
      "Done:  429 / 510\n",
      "Done:  430 / 510\n",
      "Done:  431 / 510\n",
      "Done:  432 / 510\n",
      "Done:  433 / 510\n",
      "Done:  434 / 510\n",
      "Done:  435 / 510\n",
      "Done:  436 / 510\n",
      "Done:  437 / 510\n",
      "Done:  438 / 510\n",
      "Done:  439 / 510\n",
      "Done:  440 / 510\n",
      "Done:  441 / 510\n",
      "Done:  442 / 510\n",
      "Done:  443 / 510\n",
      "Done:  444 / 510\n",
      "Done:  445 / 510\n",
      "Done:  446 / 510\n",
      "Done:  447 / 510\n",
      "Done:  448 / 510\n",
      "Done:  449 / 510\n",
      "Done:  450 / 510\n",
      "Done:  451 / 510\n",
      "Done:  452 / 510\n",
      "Done:  453 / 510\n",
      "Done:  454 / 510\n",
      "Done:  455 / 510\n",
      "Done:  456 / 510\n",
      "Done:  457 / 510\n",
      "Done:  458 / 510\n",
      "Done:  459 / 510\n",
      "Done:  460 / 510\n",
      "Done:  461 / 510\n",
      "Done:  462 / 510\n",
      "Done:  463 / 510\n",
      "Done:  464 / 510\n",
      "Done:  465 / 510\n",
      "Done:  466 / 510\n",
      "Done:  467 / 510\n",
      "Done:  468 / 510\n",
      "Done:  469 / 510\n",
      "Done:  470 / 510\n",
      "Done:  471 / 510\n",
      "Done:  472 / 510\n",
      "Done:  473 / 510\n",
      "Done:  474 / 510\n",
      "Done:  475 / 510\n",
      "Done:  476 / 510\n",
      "Done:  477 / 510\n",
      "Done:  478 / 510\n",
      "Done:  479 / 510\n",
      "Done:  480 / 510\n",
      "Done:  481 / 510\n",
      "Done:  482 / 510\n",
      "Done:  483 / 510\n",
      "Done:  484 / 510\n",
      "Done:  485 / 510\n",
      "Done:  486 / 510\n",
      "Done:  487 / 510\n",
      "Done:  488 / 510\n",
      "Done:  489 / 510\n",
      "Done:  490 / 510\n",
      "Done:  491 / 510\n",
      "Done:  492 / 510\n",
      "Done:  493 / 510\n",
      "Done:  494 / 510\n",
      "Done:  495 / 510\n",
      "Done:  496 / 510\n",
      "Done:  497 / 510\n",
      "Done:  498 / 510\n",
      "Done:  499 / 510\n",
      "Done:  500 / 510\n",
      "Done:  501 / 510\n",
      "Done:  502 / 510\n",
      "Done:  503 / 510\n",
      "Done:  504 / 510\n",
      "Done:  505 / 510\n",
      "Done:  506 / 510\n",
      "Done:  507 / 510\n",
      "Done:  508 / 510\n",
      "Done:  509 / 510\n",
      "Done:  510 / 510\n"
     ]
    }
   ],
   "source": [
    "actual_analysis = test_dataset['Output']\n",
    "predicted_analysis = []\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for entry in test_dataset['Input']:\n",
    "    input_ids = tokenizer(entry, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,         \n",
    "        num_beams=5,           \n",
    "        repetition_penalty=3.0, \n",
    "        length_penalty=1.0,     \n",
    "        top_k=50,               \n",
    "        top_p=0.95,             \n",
    "        early_stopping=True\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    predicted_analysis.append(decoded_output)\n",
    "    print(\"Done: \", len(predicted_analysis), \"/\", len(test_dataset['Input']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 38.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.64 seconds, 66.79 sentences/sec\n",
      "BERT Score Precision: tensor(0.8655)\n",
      "BERT Score Recall: tensor(0.8548)\n",
      "BERT Score F1: tensor(0.8601)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(predicted_analysis, actual_analysis, lang='en', verbose=True)\n",
    "\n",
    "print(\"BERT Score Precision:\", P.mean())\n",
    "print(\"BERT Score Recall:\", R.mean())\n",
    "print(\"BERT Score F1:\", F1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from bert_score import score\n",
    "\n",
    "precision_mean = P.mean()\n",
    "recall_mean = R.mean()\n",
    "f1_mean = F1.mean()\n",
    "\n",
    "labels = [\"Precision\", \"Recall\", \"F1\"]\n",
    "values = [0.8655, 0.8548, 0.8601]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, values, color=[\"#91A195\", \"#D3A6A1\", \"#A1B0D3\"])\n",
    "plt.ylim(0, 1)  \n",
    "plt.title(\"BERT Score Results\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.xlabel(\"Metrics\", fontsize=12)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Themes:\n",
      "Theme 1: ['nihilistic reflections', 'the Villa Borghese', 'the Montparnasse neighborhood', 'a man', 'a brooding philosophical type', 'he', 'various excuses', 'he', 'an aspiring writer', 'he', 'an “artist', 'a vaguer sense']\n",
      "Representative for Theme 1: a vaguer sense\n",
      "Theme 2: ['this welter', 'details', 'He', 'who', 'Henry', 'him', 'breakfast', 'Henry', 'no money', 'his years', 'that ambition', 'his sense', 'himself']\n",
      "Representative for Theme 2: his years\n",
      "Theme 3: ['Henry’s life', 'Paris', 'Boris', 'Boris', 'Henry’s repeated requests', 'Paris']\n",
      "Representative for Theme 3: Boris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import spacy\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_tokenizer')\n",
    "model.to('cuda')\n",
    "\n",
    "# Function to get T5 base embeddings with mean pooling\n",
    "def get_t5_embeddings(text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256).input_ids.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_encoder()(input_ids).last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "        mean_pooled = embeddings.mean(dim=1)  # Reduce to (batch_size, hidden_size)\n",
    "    return mean_pooled.cpu().numpy().squeeze()  # Return as numpy array\n",
    "\n",
    "# Function to extract key phrases using spaCy\n",
    "def extract_key_phrases(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "# Example input text\n",
    "example_text = \"\"\"Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. \n",
    "He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. \n",
    "Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. \n",
    "Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, \n",
    "though not relinquishing his sense of himself as an “artist” in a vaguer sense.\"\"\"\n",
    "\n",
    "# Step 1: Extract key phrases\n",
    "key_phrases = extract_key_phrases(example_text)\n",
    "\n",
    "# Step 2: Generate embeddings for key phrases\n",
    "phrase_embeddings = [get_t5_embeddings(phrase) for phrase in key_phrases]\n",
    "phrase_embeddings = np.array(phrase_embeddings)  # Convert to numpy array\n",
    "\n",
    "# Step 3: Apply k-means clustering\n",
    "num_clusters = 3\n",
    "clustering_model = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clustering_model.fit(phrase_embeddings)\n",
    "cluster_labels = clustering_model.labels_\n",
    "\n",
    "# Group phrases by cluster\n",
    "clusters = {i: [] for i in range(num_clusters)}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    clusters[label].append(key_phrases[i])\n",
    "\n",
    "# Step 4: Identify theme representatives (closest to centroid)\n",
    "theme_representatives = []\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
    "    cluster_embeddings = phrase_embeddings[cluster_indices]\n",
    "    cluster_centroid = clustering_model.cluster_centers_[cluster_id]\n",
    "\n",
    "    # Compute distances to centroid\n",
    "    distances = np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "    closest_idx = cluster_indices[np.argmin(distances)]  # Find closest phrase\n",
    "    theme_representatives.append(key_phrases[closest_idx])\n",
    "\n",
    "# Step 5: Output results\n",
    "print(\"\\nIdentified Themes:\")\n",
    "for cluster_id, phrases in clusters.items():\n",
    "    print(f\"Theme {cluster_id + 1}: {phrases}\")\n",
    "    print(f\"Representative for Theme {cluster_id + 1}: {theme_representatives[cluster_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5_base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_base_tokenizer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  1 / 510\n",
      "Done:  2 / 510\n",
      "Done:  3 / 510\n",
      "Done:  4 / 510\n",
      "Done:  5 / 510\n",
      "Done:  6 / 510\n",
      "Done:  7 / 510\n",
      "Done:  8 / 510\n",
      "Done:  9 / 510\n",
      "Done:  10 / 510\n",
      "Done:  11 / 510\n",
      "Done:  12 / 510\n",
      "Done:  13 / 510\n",
      "Done:  14 / 510\n",
      "Done:  15 / 510\n",
      "Done:  16 / 510\n",
      "Done:  17 / 510\n",
      "Done:  18 / 510\n",
      "Done:  19 / 510\n",
      "Done:  20 / 510\n",
      "Done:  21 / 510\n",
      "Done:  22 / 510\n",
      "Done:  23 / 510\n",
      "Done:  24 / 510\n",
      "Done:  25 / 510\n",
      "Done:  26 / 510\n",
      "Done:  27 / 510\n",
      "Done:  28 / 510\n",
      "Done:  29 / 510\n",
      "Done:  30 / 510\n",
      "Done:  31 / 510\n",
      "Done:  32 / 510\n",
      "Done:  33 / 510\n",
      "Done:  34 / 510\n",
      "Done:  35 / 510\n",
      "Done:  36 / 510\n",
      "Done:  37 / 510\n",
      "Done:  38 / 510\n",
      "Done:  39 / 510\n",
      "Done:  40 / 510\n",
      "Done:  41 / 510\n",
      "Done:  42 / 510\n",
      "Done:  43 / 510\n",
      "Done:  44 / 510\n",
      "Done:  45 / 510\n",
      "Done:  46 / 510\n",
      "Done:  47 / 510\n",
      "Done:  48 / 510\n",
      "Done:  49 / 510\n",
      "Done:  50 / 510\n",
      "Done:  51 / 510\n",
      "Done:  52 / 510\n",
      "Done:  53 / 510\n",
      "Done:  54 / 510\n",
      "Done:  55 / 510\n",
      "Done:  56 / 510\n",
      "Done:  57 / 510\n",
      "Done:  58 / 510\n",
      "Done:  59 / 510\n",
      "Done:  60 / 510\n",
      "Done:  61 / 510\n",
      "Done:  62 / 510\n",
      "Done:  63 / 510\n",
      "Done:  64 / 510\n",
      "Done:  65 / 510\n",
      "Done:  66 / 510\n",
      "Done:  67 / 510\n",
      "Done:  68 / 510\n",
      "Done:  69 / 510\n",
      "Done:  70 / 510\n",
      "Done:  71 / 510\n",
      "Done:  72 / 510\n",
      "Done:  73 / 510\n",
      "Done:  74 / 510\n",
      "Done:  75 / 510\n",
      "Done:  76 / 510\n",
      "Done:  77 / 510\n",
      "Done:  78 / 510\n",
      "Done:  79 / 510\n",
      "Done:  80 / 510\n",
      "Done:  81 / 510\n",
      "Done:  82 / 510\n",
      "Done:  83 / 510\n",
      "Done:  84 / 510\n",
      "Done:  85 / 510\n",
      "Done:  86 / 510\n",
      "Done:  87 / 510\n",
      "Done:  88 / 510\n",
      "Done:  89 / 510\n",
      "Done:  90 / 510\n",
      "Done:  91 / 510\n",
      "Done:  92 / 510\n",
      "Done:  93 / 510\n",
      "Done:  94 / 510\n",
      "Done:  95 / 510\n",
      "Done:  96 / 510\n",
      "Done:  97 / 510\n",
      "Done:  98 / 510\n",
      "Done:  99 / 510\n",
      "Done:  100 / 510\n",
      "Done:  101 / 510\n",
      "Done:  102 / 510\n",
      "Done:  103 / 510\n",
      "Done:  104 / 510\n",
      "Done:  105 / 510\n",
      "Done:  106 / 510\n",
      "Done:  107 / 510\n",
      "Done:  108 / 510\n",
      "Done:  109 / 510\n",
      "Done:  110 / 510\n",
      "Done:  111 / 510\n",
      "Done:  112 / 510\n",
      "Done:  113 / 510\n",
      "Done:  114 / 510\n",
      "Done:  115 / 510\n",
      "Done:  116 / 510\n",
      "Done:  117 / 510\n",
      "Done:  118 / 510\n",
      "Done:  119 / 510\n",
      "Done:  120 / 510\n",
      "Done:  121 / 510\n",
      "Done:  122 / 510\n",
      "Done:  123 / 510\n",
      "Done:  124 / 510\n",
      "Done:  125 / 510\n",
      "Done:  126 / 510\n",
      "Done:  127 / 510\n",
      "Done:  128 / 510\n",
      "Done:  129 / 510\n",
      "Done:  130 / 510\n",
      "Done:  131 / 510\n",
      "Done:  132 / 510\n",
      "Done:  133 / 510\n",
      "Done:  134 / 510\n",
      "Done:  135 / 510\n",
      "Done:  136 / 510\n",
      "Done:  137 / 510\n",
      "Done:  138 / 510\n",
      "Done:  139 / 510\n",
      "Done:  140 / 510\n",
      "Done:  141 / 510\n",
      "Done:  142 / 510\n",
      "Done:  143 / 510\n",
      "Done:  144 / 510\n",
      "Done:  145 / 510\n",
      "Done:  146 / 510\n",
      "Done:  147 / 510\n",
      "Done:  148 / 510\n",
      "Done:  149 / 510\n",
      "Done:  150 / 510\n",
      "Done:  151 / 510\n",
      "Done:  152 / 510\n",
      "Done:  153 / 510\n",
      "Done:  154 / 510\n",
      "Done:  155 / 510\n",
      "Done:  156 / 510\n",
      "Done:  157 / 510\n",
      "Done:  158 / 510\n",
      "Done:  159 / 510\n",
      "Done:  160 / 510\n",
      "Done:  161 / 510\n",
      "Done:  162 / 510\n",
      "Done:  163 / 510\n",
      "Done:  164 / 510\n",
      "Done:  165 / 510\n",
      "Done:  166 / 510\n",
      "Done:  167 / 510\n",
      "Done:  168 / 510\n",
      "Done:  169 / 510\n",
      "Done:  170 / 510\n",
      "Done:  171 / 510\n",
      "Done:  172 / 510\n",
      "Done:  173 / 510\n",
      "Done:  174 / 510\n",
      "Done:  175 / 510\n",
      "Done:  176 / 510\n",
      "Done:  177 / 510\n",
      "Done:  178 / 510\n",
      "Done:  179 / 510\n",
      "Done:  180 / 510\n",
      "Done:  181 / 510\n",
      "Done:  182 / 510\n",
      "Done:  183 / 510\n",
      "Done:  184 / 510\n",
      "Done:  185 / 510\n",
      "Done:  186 / 510\n",
      "Done:  187 / 510\n",
      "Done:  188 / 510\n",
      "Done:  189 / 510\n",
      "Done:  190 / 510\n",
      "Done:  191 / 510\n",
      "Done:  192 / 510\n",
      "Done:  193 / 510\n",
      "Done:  194 / 510\n",
      "Done:  195 / 510\n",
      "Done:  196 / 510\n",
      "Done:  197 / 510\n",
      "Done:  198 / 510\n",
      "Done:  199 / 510\n",
      "Done:  200 / 510\n",
      "Done:  201 / 510\n",
      "Done:  202 / 510\n",
      "Done:  203 / 510\n",
      "Done:  204 / 510\n",
      "Done:  205 / 510\n",
      "Done:  206 / 510\n",
      "Done:  207 / 510\n",
      "Done:  208 / 510\n",
      "Done:  209 / 510\n",
      "Done:  210 / 510\n",
      "Done:  211 / 510\n",
      "Done:  212 / 510\n",
      "Done:  213 / 510\n",
      "Done:  214 / 510\n",
      "Done:  215 / 510\n",
      "Done:  216 / 510\n",
      "Done:  217 / 510\n",
      "Done:  218 / 510\n",
      "Done:  219 / 510\n",
      "Done:  220 / 510\n",
      "Done:  221 / 510\n",
      "Done:  222 / 510\n",
      "Done:  223 / 510\n",
      "Done:  224 / 510\n",
      "Done:  225 / 510\n",
      "Done:  226 / 510\n",
      "Done:  227 / 510\n",
      "Done:  228 / 510\n",
      "Done:  229 / 510\n",
      "Done:  230 / 510\n",
      "Done:  231 / 510\n",
      "Done:  232 / 510\n",
      "Done:  233 / 510\n",
      "Done:  234 / 510\n",
      "Done:  235 / 510\n",
      "Done:  236 / 510\n",
      "Done:  237 / 510\n",
      "Done:  238 / 510\n",
      "Done:  239 / 510\n",
      "Done:  240 / 510\n",
      "Done:  241 / 510\n",
      "Done:  242 / 510\n",
      "Done:  243 / 510\n",
      "Done:  244 / 510\n",
      "Done:  245 / 510\n",
      "Done:  246 / 510\n",
      "Done:  247 / 510\n",
      "Done:  248 / 510\n",
      "Done:  249 / 510\n",
      "Done:  250 / 510\n",
      "Done:  251 / 510\n",
      "Done:  252 / 510\n",
      "Done:  253 / 510\n",
      "Done:  254 / 510\n",
      "Done:  255 / 510\n",
      "Done:  256 / 510\n",
      "Done:  257 / 510\n",
      "Done:  258 / 510\n",
      "Done:  259 / 510\n",
      "Done:  260 / 510\n",
      "Done:  261 / 510\n",
      "Done:  262 / 510\n",
      "Done:  263 / 510\n",
      "Done:  264 / 510\n",
      "Done:  265 / 510\n",
      "Done:  266 / 510\n",
      "Done:  267 / 510\n",
      "Done:  268 / 510\n",
      "Done:  269 / 510\n",
      "Done:  270 / 510\n",
      "Done:  271 / 510\n",
      "Done:  272 / 510\n",
      "Done:  273 / 510\n",
      "Done:  274 / 510\n",
      "Done:  275 / 510\n",
      "Done:  276 / 510\n",
      "Done:  277 / 510\n",
      "Done:  278 / 510\n",
      "Done:  279 / 510\n",
      "Done:  280 / 510\n",
      "Done:  281 / 510\n",
      "Done:  282 / 510\n",
      "Done:  283 / 510\n",
      "Done:  284 / 510\n",
      "Done:  285 / 510\n",
      "Done:  286 / 510\n",
      "Done:  287 / 510\n",
      "Done:  288 / 510\n",
      "Done:  289 / 510\n",
      "Done:  290 / 510\n",
      "Done:  291 / 510\n",
      "Done:  292 / 510\n",
      "Done:  293 / 510\n",
      "Done:  294 / 510\n",
      "Done:  295 / 510\n",
      "Done:  296 / 510\n",
      "Done:  297 / 510\n",
      "Done:  298 / 510\n",
      "Done:  299 / 510\n",
      "Done:  300 / 510\n",
      "Done:  301 / 510\n",
      "Done:  302 / 510\n",
      "Done:  303 / 510\n",
      "Done:  304 / 510\n",
      "Done:  305 / 510\n",
      "Done:  306 / 510\n",
      "Done:  307 / 510\n",
      "Done:  308 / 510\n",
      "Done:  309 / 510\n",
      "Done:  310 / 510\n",
      "Done:  311 / 510\n",
      "Done:  312 / 510\n",
      "Done:  313 / 510\n",
      "Done:  314 / 510\n",
      "Done:  315 / 510\n",
      "Done:  316 / 510\n",
      "Done:  317 / 510\n",
      "Done:  318 / 510\n",
      "Done:  319 / 510\n",
      "Done:  320 / 510\n",
      "Done:  321 / 510\n",
      "Done:  322 / 510\n",
      "Done:  323 / 510\n",
      "Done:  324 / 510\n",
      "Done:  325 / 510\n",
      "Done:  326 / 510\n",
      "Done:  327 / 510\n",
      "Done:  328 / 510\n",
      "Done:  329 / 510\n",
      "Done:  330 / 510\n",
      "Done:  331 / 510\n",
      "Done:  332 / 510\n",
      "Done:  333 / 510\n",
      "Done:  334 / 510\n",
      "Done:  335 / 510\n",
      "Done:  336 / 510\n",
      "Done:  337 / 510\n",
      "Done:  338 / 510\n",
      "Done:  339 / 510\n",
      "Done:  340 / 510\n",
      "Done:  341 / 510\n",
      "Done:  342 / 510\n",
      "Done:  343 / 510\n",
      "Done:  344 / 510\n",
      "Done:  345 / 510\n",
      "Done:  346 / 510\n",
      "Done:  347 / 510\n",
      "Done:  348 / 510\n",
      "Done:  349 / 510\n",
      "Done:  350 / 510\n",
      "Done:  351 / 510\n",
      "Done:  352 / 510\n",
      "Done:  353 / 510\n",
      "Done:  354 / 510\n",
      "Done:  355 / 510\n",
      "Done:  356 / 510\n",
      "Done:  357 / 510\n",
      "Done:  358 / 510\n",
      "Done:  359 / 510\n",
      "Done:  360 / 510\n",
      "Done:  361 / 510\n",
      "Done:  362 / 510\n",
      "Done:  363 / 510\n",
      "Done:  364 / 510\n",
      "Done:  365 / 510\n",
      "Done:  366 / 510\n",
      "Done:  367 / 510\n",
      "Done:  368 / 510\n",
      "Done:  369 / 510\n",
      "Done:  370 / 510\n",
      "Done:  371 / 510\n",
      "Done:  372 / 510\n",
      "Done:  373 / 510\n",
      "Done:  374 / 510\n",
      "Done:  375 / 510\n",
      "Done:  376 / 510\n",
      "Done:  377 / 510\n",
      "Done:  378 / 510\n",
      "Done:  379 / 510\n",
      "Done:  380 / 510\n",
      "Done:  381 / 510\n",
      "Done:  382 / 510\n",
      "Done:  383 / 510\n",
      "Done:  384 / 510\n",
      "Done:  385 / 510\n",
      "Done:  386 / 510\n",
      "Done:  387 / 510\n",
      "Done:  388 / 510\n",
      "Done:  389 / 510\n",
      "Done:  390 / 510\n",
      "Done:  391 / 510\n",
      "Done:  392 / 510\n",
      "Done:  393 / 510\n",
      "Done:  394 / 510\n",
      "Done:  395 / 510\n",
      "Done:  396 / 510\n",
      "Done:  397 / 510\n",
      "Done:  398 / 510\n",
      "Done:  399 / 510\n",
      "Done:  400 / 510\n",
      "Done:  401 / 510\n",
      "Done:  402 / 510\n",
      "Done:  403 / 510\n",
      "Done:  404 / 510\n",
      "Done:  405 / 510\n",
      "Done:  406 / 510\n",
      "Done:  407 / 510\n",
      "Done:  408 / 510\n",
      "Done:  409 / 510\n",
      "Done:  410 / 510\n",
      "Done:  411 / 510\n",
      "Done:  412 / 510\n",
      "Done:  413 / 510\n",
      "Done:  414 / 510\n",
      "Done:  415 / 510\n",
      "Done:  416 / 510\n",
      "Done:  417 / 510\n",
      "Done:  418 / 510\n",
      "Done:  419 / 510\n",
      "Done:  420 / 510\n",
      "Done:  421 / 510\n",
      "Done:  422 / 510\n",
      "Done:  423 / 510\n",
      "Done:  424 / 510\n",
      "Done:  425 / 510\n",
      "Done:  426 / 510\n",
      "Done:  427 / 510\n",
      "Done:  428 / 510\n",
      "Done:  429 / 510\n",
      "Done:  430 / 510\n",
      "Done:  431 / 510\n",
      "Done:  432 / 510\n",
      "Done:  433 / 510\n",
      "Done:  434 / 510\n",
      "Done:  435 / 510\n",
      "Done:  436 / 510\n",
      "Done:  437 / 510\n",
      "Done:  438 / 510\n",
      "Done:  439 / 510\n",
      "Done:  440 / 510\n",
      "Done:  441 / 510\n",
      "Done:  442 / 510\n",
      "Done:  443 / 510\n",
      "Done:  444 / 510\n",
      "Done:  445 / 510\n",
      "Done:  446 / 510\n",
      "Done:  447 / 510\n",
      "Done:  448 / 510\n",
      "Done:  449 / 510\n",
      "Done:  450 / 510\n",
      "Done:  451 / 510\n",
      "Done:  452 / 510\n",
      "Done:  453 / 510\n",
      "Done:  454 / 510\n",
      "Done:  455 / 510\n",
      "Done:  456 / 510\n",
      "Done:  457 / 510\n",
      "Done:  458 / 510\n",
      "Done:  459 / 510\n",
      "Done:  460 / 510\n",
      "Done:  461 / 510\n",
      "Done:  462 / 510\n",
      "Done:  463 / 510\n",
      "Done:  464 / 510\n",
      "Done:  465 / 510\n",
      "Done:  466 / 510\n",
      "Done:  467 / 510\n",
      "Done:  468 / 510\n",
      "Done:  469 / 510\n",
      "Done:  470 / 510\n",
      "Done:  471 / 510\n",
      "Done:  472 / 510\n",
      "Done:  473 / 510\n",
      "Done:  474 / 510\n",
      "Done:  475 / 510\n",
      "Done:  476 / 510\n",
      "Done:  477 / 510\n",
      "Done:  478 / 510\n",
      "Done:  479 / 510\n",
      "Done:  480 / 510\n",
      "Done:  481 / 510\n",
      "Done:  482 / 510\n",
      "Done:  483 / 510\n",
      "Done:  484 / 510\n",
      "Done:  485 / 510\n",
      "Done:  486 / 510\n",
      "Done:  487 / 510\n",
      "Done:  488 / 510\n",
      "Done:  489 / 510\n",
      "Done:  490 / 510\n",
      "Done:  491 / 510\n",
      "Done:  492 / 510\n",
      "Done:  493 / 510\n",
      "Done:  494 / 510\n",
      "Done:  495 / 510\n",
      "Done:  496 / 510\n",
      "Done:  497 / 510\n",
      "Done:  498 / 510\n",
      "Done:  499 / 510\n",
      "Done:  500 / 510\n",
      "Done:  501 / 510\n",
      "Done:  502 / 510\n",
      "Done:  503 / 510\n",
      "Done:  504 / 510\n",
      "Done:  505 / 510\n",
      "Done:  506 / 510\n",
      "Done:  507 / 510\n",
      "Done:  508 / 510\n",
      "Done:  509 / 510\n",
      "Done:  510 / 510\n"
     ]
    }
   ],
   "source": [
    "actual_analysis = test_dataset['Output']\n",
    "predicted_analysis = []\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for entry in test_dataset['Input']:\n",
    "    input_ids = tokenizer(entry, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,         \n",
    "        num_beams=5,           \n",
    "        repetition_penalty=3.0, \n",
    "        length_penalty=1.0,     \n",
    "        top_k=50,               \n",
    "        top_p=0.95,             \n",
    "        early_stopping=True\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    predicted_analysis.append(decoded_output)\n",
    "    print(\"Done: \", len(predicted_analysis), \"/\", len(test_dataset['Input']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.55 seconds, 67.57 sentences/sec\n",
      "BERT Score Precision: tensor(0.8676)\n",
      "BERT Score Recall: tensor(0.8546)\n",
      "BERT Score F1: tensor(0.8609)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(predicted_analysis, actual_analysis, lang='en', verbose=True)\n",
    "\n",
    "print(\"BERT Score Precision:\", P.mean())\n",
    "print(\"BERT Score Recall:\", R.mean())\n",
    "print(\"BERT Score F1:\", F1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthony does everything he can to rationalize his own position in life. His attempts rely on his ability to demonstrate himself as superior to Dick, which is difficult now that Dick has made a name for himself. Anthony settles for disgust at Dick’s self-satisfaction, but he can’t deny that Dick has far more reason than Anthony for self-satisfaction. Dick’s continued hard work, even after a modicum of success, contrasts with Anthony’s pathetic drunkenness in the back of the cab.\n",
      "Anthony’s disapproval of Dick’s poetry is a reflection of his own inability to express himself through the novel. Dick, on the other hand, believes that beauty can only be developed through the novel. This contrasts with Dick’s contempt for Richard Caramel and Mark Twain’s work.\n"
     ]
    }
   ],
   "source": [
    "print(actual_analysis[1])\n",
    "print(predicted_analysis[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from bert_score import score\n",
    "\n",
    "precision_mean = P.mean()\n",
    "recall_mean = R.mean()\n",
    "f1_mean = F1.mean()\n",
    "\n",
    "labels = [\"Precision\", \"Recall\", \"F1\"]\n",
    "values = [0.8676, 0.8546, 0.8609]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, values, color=[\"#91A195\", \"#D3A6A1\", \"#A1B0D3\"])\n",
    "plt.ylim(0, 1)  \n",
    "plt.title(\"BERT Score Results\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.xlabel(\"Metrics\", fontsize=12)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Themes:\n",
      "Theme 1: ['this welter', 'a man', 'a brooding philosophical type', 'an aspiring writer', 'a vaguer sense']\n",
      "Representative for Theme 1: a vaguer sense\n",
      "Theme 2: ['details', 'Paris', 'Boris', 'Boris', 'Henry', 'him', 'breakfast', 'Henry', 'no money', 'his years', 'Paris', 'his sense', 'himself']\n",
      "Representative for Theme 2: Boris\n",
      "Theme 3: ['nihilistic reflections', 'Henry’s life', 'He', 'the Villa Borghese', 'the Montparnasse neighborhood', 'who', 'he', 'various excuses', 'Henry’s repeated requests', 'he', 'he', 'that ambition', 'an “artist']\n",
      "Representative for Theme 3: Henry’s life\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import spacy\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('fine_tuned_t5_base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_base_tokenizer')\n",
    "model.to('cuda')\n",
    "\n",
    "# Function to get T5 base embeddings with mean pooling\n",
    "def get_t5_base_embeddings(text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256).input_ids.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_encoder()(input_ids).last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "        mean_pooled = embeddings.mean(dim=1)  # Reduce to (batch_size, hidden_size)\n",
    "    return mean_pooled.cpu().numpy().squeeze()  # Return as numpy array\n",
    "\n",
    "# Function to extract key phrases using spaCy\n",
    "def extract_key_phrases(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "# Example input text\n",
    "example_text = \"\"\"Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. \n",
    "He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. \n",
    "Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. \n",
    "Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, \n",
    "though not relinquishing his sense of himself as an “artist” in a vaguer sense.\"\"\"\n",
    "\n",
    "# Step 1: Extract key phrases\n",
    "key_phrases = extract_key_phrases(example_text)\n",
    "\n",
    "# Step 2: Generate embeddings for key phrases\n",
    "phrase_embeddings = [get_t5_base_embeddings(phrase) for phrase in key_phrases]\n",
    "phrase_embeddings = np.array(phrase_embeddings)  # Convert to numpy array\n",
    "\n",
    "# Step 3: Apply k-means clustering\n",
    "num_clusters = 3\n",
    "clustering_model = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clustering_model.fit(phrase_embeddings)\n",
    "cluster_labels = clustering_model.labels_\n",
    "\n",
    "# Group phrases by cluster\n",
    "clusters = {i: [] for i in range(num_clusters)}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    clusters[label].append(key_phrases[i])\n",
    "\n",
    "# Step 4: Identify theme representatives (closest to centroid)\n",
    "theme_representatives = []\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
    "    cluster_embeddings = phrase_embeddings[cluster_indices]\n",
    "    cluster_centroid = clustering_model.cluster_centers_[cluster_id]\n",
    "\n",
    "    # Compute distances to centroid\n",
    "    distances = np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "    closest_idx = cluster_indices[np.argmin(distances)]  # Find closest phrase\n",
    "    theme_representatives.append(key_phrases[closest_idx])\n",
    "\n",
    "# Step 5: Output results\n",
    "print(\"\\nIdentified Themes:\")\n",
    "for cluster_id, phrases in clusters.items():\n",
    "    print(f\"Theme {cluster_id + 1}: {phrases}\")\n",
    "    print(f\"Representative for Theme {cluster_id + 1}: {theme_representatives[cluster_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keybert) (1.26.0)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keybert) (13.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keybert) (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keybert) (3.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from rich>=10.4.0->keybert) (2.17.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.48.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (2.2.2+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.27.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: keybert\n",
      "Successfully installed keybert-0.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Themes:\n",
      "Theme 1: ['paris', 'writer', 'villa', 'ambition', 'artist', 'life']\n",
      "Representative for Theme 1: artist\n",
      "Theme 2: ['henry', 'boris', 'borghese']\n",
      "Representative for Theme 2: boris\n",
      "Theme 3: ['brooding']\n",
      "Representative for Theme 3: brooding\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from keybert import KeyBERT\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "# Load your fine-tuned T5 model and tokenizer\n",
    "model_path = \"fine_tuned_t5_base\"  # Update with the correct model path\n",
    "tokenizer_path = \"fine_tuned_t5_base_tokenizer\"  # Update with the correct tokenizer path\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Key phrase extraction using KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "def extract_key_phrases(text):\n",
    "    return [phrase for phrase, _ in kw_model.extract_keywords(text, top_n=10)]\n",
    "\n",
    "# Generate embeddings using your fine-tuned T5 model\n",
    "def get_t5_embeddings(text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256).input_ids.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_encoder()(input_ids).last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
    "        mean_pooled = embeddings.mean(dim=1)  # Mean pooling over seq_len -> Shape: (batch_size, hidden_size)\n",
    "    return mean_pooled.cpu().numpy().squeeze()  # Convert to numpy array\n",
    "\n",
    "# Example input text\n",
    "example_text = \"\"\"\n",
    "Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. \n",
    "He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. \n",
    "Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. \n",
    "Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, \n",
    "though not relinquishing his sense of himself as an “artist” in a vaguer sense.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Extract key phrases\n",
    "key_phrases = extract_key_phrases(example_text)\n",
    "\n",
    "# Step 2: Generate embeddings for key phrases\n",
    "phrase_embeddings = np.array([get_t5_embeddings(phrase) for phrase in key_phrases])\n",
    "\n",
    "# Step 3: Apply clustering\n",
    "num_clusters = 3  # Adjust as needed\n",
    "clustering_model = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "cluster_labels = clustering_model.fit_predict(phrase_embeddings)\n",
    "\n",
    "# Step 4: Group phrases by cluster\n",
    "clusters = {i: [] for i in range(num_clusters)}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    clusters[label].append(key_phrases[i])\n",
    "\n",
    "# Step 5: Identify representatives for each theme\n",
    "theme_representatives = []\n",
    "for cluster_id, phrases in clusters.items():\n",
    "    cluster_embeddings = np.array([get_t5_embeddings(phrase) for phrase in phrases])\n",
    "    cluster_centroid = cluster_embeddings.mean(axis=0)\n",
    "    distances = np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "    representative_idx = np.argmin(distances)\n",
    "    theme_representatives.append(phrases[representative_idx])\n",
    "\n",
    "# Output results\n",
    "print(\"\\nIdentified Themes:\")\n",
    "for cluster_id, phrases in clusters.items():\n",
    "    print(f\"Theme {cluster_id + 1}: {phrases}\")\n",
    "    print(f\"Representative for Theme {cluster_id + 1}: {theme_representatives[cluster_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('test_selenium.csv')\n",
    "data['Input'] = data['Summary']\n",
    "data['Output'] = data['Analysis']\n",
    "\n",
    "data[['Input', 'Output']].to_csv('fine_tuning_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he doesn’t relinquish his sense of himself as an “artist.”\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Out of this welter of nihilistic reflections, details begin to emerge about Henry’s life in Paris. He lives in the Villa Borghese in the Montparnasse neighborhood with a man named Boris, who’s also a brooding philosophical type. Boris seems to be allowing Henry to stay with him for free, though he employs various excuses to avoid Henry’s repeated requests for breakfast. Henry has no money at all; he has spent his years in Paris as an aspiring writer, but he seems to be letting go of that ambition, though not relinquishing his sense of himself as an “artist” in a vaguer sense.\"\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(\"cuda\")  # Move to GPU if available\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,         # Allow for longer outputs if needed\n",
    "    num_beams=10,           # Increase beams for more refined results\n",
    "    repetition_penalty=2.0, # Penalize repetitive outputs\n",
    "    length_penalty=2.0,     # Encourage longer outputs\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4126/4126 [00:14<00:00, 282.96 examples/s]\n",
      "Map: 100%|██████████| 459/459 [00:01<00:00, 281.60 examples/s]\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 343.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n",
      "\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Move model to GPU and enable gradient checkpointing\u001b[39;00m\n",
      "\u001b[1;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39mgradient_checkpointing_enable()\n",
      "\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Step 4: Training Arguments\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\modeling_utils.py:3110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   3105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n",
      "\u001b[0;32m   3106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   3107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   3108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   3109\u001b[0m         )\n",
      "\u001b[1;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n",
      "\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "\u001b[1;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n",
      "\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n",
      "\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n",
      "\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
      "\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n",
      "\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n",
      "\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n",
      "\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n",
      "\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n",
      "\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
      "\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n",
      "\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n",
      "\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n",
      "\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n",
      "\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n",
      "\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
      "\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n",
      "\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n",
      "\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n",
      "\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n",
      "\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n",
      "\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n",
      "\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n",
      "\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n",
      "\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n",
      "\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 343.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Clear CUDA cache and optimize memory usage\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Step 1: Load and Preprocess Dataset\n",
    "data_path = \"fine_tuning_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns = [\"Input\", \"Output\"]\n",
    "\n",
    "# Split dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Step 2: Tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"Input\"], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        examples[\"Output\"], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\"])\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\"])\n",
    "\n",
    "# Step 3: Load Model\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.encoder.vocab_size\n",
    "\n",
    "# Move model to GPU and enable gradient checkpointing\n",
    "model = model.to(\"cuda\")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Step 4: Training Arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bert2bert_analysis\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,  # Reduce batch size\n",
    "    per_device_eval_batch_size=4,  # Reduce batch size\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch sizes\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Step 5: Define Metrics\n",
    "from datasets import load_metric\n",
    "\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "# Step 6: Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Step 7: Train\n",
    "trainer.train()\n",
    "\n",
    "# Step 8: Save Model and Tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_bert2bert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bert2bert_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert2Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4126/4126 [00:14<00:00, 282.96 examples/s]\n",
      "Map: 100%|██████████| 459/459 [00:01<00:00, 281.60 examples/s]\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 343.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Move model to GPU and enable gradient checkpointing\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39mgradient_checkpointing_enable()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Step 4: Training Arguments\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\modeling_utils.py:3110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3109\u001b[0m         )\n\u001b[1;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 343.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Clear CUDA cache and optimize memory usage\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Step 1: Load and Preprocess Dataset\n",
    "data_path = \"fine_tuning_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns = [\"Input\", \"Output\"]\n",
    "\n",
    "# Split dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Step 2: Tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"Input\"], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        examples[\"Output\"], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\"])\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\"])\n",
    "\n",
    "# Step 3: Load Model\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.encoder.vocab_size\n",
    "\n",
    "# Move model to GPU and enable gradient checkpointing\n",
    "model = model.to(\"cuda\")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Step 4: Training Arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bert2bert_analysis\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,  # Reduce batch size\n",
    "    per_device_eval_batch_size=4,  # Reduce batch size\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch sizes\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Step 5: Define Metrics\n",
    "from datasets import load_metric\n",
    "\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "# Step 6: Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Step 7: Train\n",
    "trainer.train()\n",
    "\n",
    "# Step 8: Save Model and Tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_bert2bert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bert2bert_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4585/4585 [00:07<00:00, 644.59 examples/s]\n",
      "Map: 100%|██████████| 510/510 [00:00<00:00, 515.67 examples/s]\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_29220\\1167386650.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:48: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='286' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [286/286 37:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.220377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input length of input_ids is 136, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Generate output\u001b[39;00m\n\u001b[0;32m     84\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\utils.py:2108\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_num_logits_to_keep() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_logits_to_keep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   2106\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_logits_to_keep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_generated_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_default_max_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# 7. Prepare the cache.\u001b[39;00m\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;66;03m# - `model_kwargs` may be updated in place with a cache as defined by the parameters in `generation_config`.\u001b[39;00m\n\u001b[0;32m   2112\u001b[0m \u001b[38;5;66;03m# - different models have a different cache name expected by the model (default = \"past_key_values\")\u001b[39;00m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;66;03m# - `max_length`, prepared above, is used to determine the maximum cache length\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;66;03m# TODO (joao): remove `user_defined_cache` after v4.47 (remove default conversion to legacy format)\u001b[39;00m\n\u001b[0;32m   2115\u001b[0m cache_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmamba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_params\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\utils.py:1411\u001b[0m, in \u001b[0;36mGenerationMixin._validate_generated_length\u001b[1;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids_length \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[0;32m   1410\u001b[0m     input_ids_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput length of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but `max_length` is set to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This can lead to unexpected behavior. You should consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1414\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m increasing `max_length` or, better yet, setting `max_new_tokens`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;66;03m# 2. Min length warnings due to unfeasible parameter combinations\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m min_length_error_suffix \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Generation will stop at the defined maximum length. You should decrease the minimum length and/or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincrease the maximum length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1421\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Input length of input_ids is 136, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Step 1: Load and Preprocess Dataset\n",
    "data_path = \"fine_tuning_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns = [\"Input\", \"Output\"]\n",
    "\n",
    "# Combine Input and Output without prefixes\n",
    "data[\"formatted\"] = data[\"Input\"] + \"\\n\" + data[\"Output\"]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(data)\n",
    "train_test_split = hf_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Step 2: Tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as pad token\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"formatted\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,  # Reduce sequence length to speed up training\n",
    "    )\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # For causal language modeling, labels = input IDs\n",
    "    return inputs\n",
    "\n",
    "# Tokenize the datasets\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\", \"formatted\"])\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"Input\", \"Output\", \"formatted\"])\n",
    "\n",
    "# Step 3: Model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Step 4: Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_analysis\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,  # Increase batch size (adjust based on GPU memory)\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,  # Reduce accumulation steps\n",
    "    num_train_epochs=2,  # Reduce epochs to save time\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=500,\n",
    "    fp16=True,  # Enable mixed precision training for faster computation\n",
    "    dataloader_num_workers=4,  # Use multiple workers for data loading\n",
    ")\n",
    "\n",
    "# Step 5: Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Step 6: Train the Model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_gpt2\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_gpt2_tokenizer\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Analysis:\n",
      "Soon after, Marlow himself falls ill. He calls his struggle with death the most unexciting contest you can imagine, and is embarrassed to discover that on his deathbed he could think of nothing to say. That's why he admires Kurtz. The man had something to say: The horror! Marlow's describes Kurtz's statement as a moral victory paid for by abominable terrors and abominable satisfactions.\n",
      "Marlow’s description of Kurtz’s speech in which he says “the horror!” makes it clear that he doesn’t want to be associated with any kind of nihilism—he just wants to make sure that everyone understands what he has said.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Generate Analysis\n",
    "input_text = \"Soon after, Marlow himself falls ill. He calls his struggle with death the most unexciting contest you can imagine, and is embarrassed to discover that on his deathbed he could think of nothing to say. That's why he admires Kurtz. The man had something to say: The horror! Marlow's describes Kurtz's statement as a moral victory paid for by abominable terrors and abominable satisfactions.\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# Generate output\n",
    "model.to(\"cuda\")\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=150,  # Generate more tokens for longer outputs\n",
    "    num_beams=5,         # Reduce beams to encourage more diversity\n",
    "    early_stopping=False, # Allow completion without stopping prematurely\n",
    "    repetition_penalty=3.0,  # Stronger penalty for repetition\n",
    "    length_penalty=1.0,   # Encourage longer and coherent outputs \n",
    "    temperature=0.9,      # Adjust temperature for more varied outputs   \n",
    "    top_k=50,             # Limit sampling to the top 50 words\n",
    "    top_p=0.95,           # Cumulative probability for token selection\n",
    ")\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated Analysis:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  1 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  2 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  3 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  4 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  5 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  6 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  7 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  8 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  9 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  10 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  11 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  12 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  13 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  14 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  15 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  16 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  17 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  18 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  19 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  20 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  21 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  22 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  23 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  24 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  25 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  26 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  27 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  28 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  29 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  30 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  31 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  32 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  33 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  34 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  35 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  36 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  37 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  38 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  39 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  40 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  41 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  42 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  43 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  44 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  45 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  46 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  47 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  48 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  49 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  50 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  51 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  52 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  53 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  54 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  55 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  56 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  57 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  58 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  59 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  60 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  61 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  62 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  63 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  64 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  65 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  66 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  67 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  68 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  69 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  70 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  71 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  72 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  73 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  74 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  75 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  76 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  77 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  78 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  79 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  80 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  81 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  82 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  83 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  84 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  85 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  86 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  87 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  88 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  89 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  90 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  91 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  92 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  93 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  94 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  95 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  96 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  97 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  98 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  99 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  100 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  101 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  102 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  103 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  104 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  105 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  106 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  107 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  108 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  109 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  110 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  111 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  112 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  113 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  114 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  115 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  116 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  117 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  118 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  119 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  120 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  121 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  122 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  123 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  124 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  125 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  126 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  127 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  128 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  129 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  130 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  131 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  132 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  133 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  134 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  135 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  136 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  137 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  138 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  139 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  140 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  141 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  142 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  143 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  144 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  145 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  146 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  147 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  148 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  149 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  150 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  151 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  152 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  153 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  154 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  155 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  156 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  157 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  158 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  159 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  160 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  161 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  162 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  163 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  164 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  165 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  166 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  167 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  168 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  169 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  170 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  171 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  172 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  173 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  174 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  175 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  176 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  177 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  178 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  179 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  180 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  181 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  182 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  183 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  184 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  185 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  186 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  187 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  188 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  189 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  190 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  191 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  192 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  193 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  194 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  195 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  196 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  197 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  198 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  199 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  200 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  201 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  202 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  203 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  204 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  205 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  206 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  207 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  208 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  209 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  210 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  211 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  212 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  213 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  214 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  215 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  216 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  217 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  218 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  219 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  220 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  221 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  222 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  223 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  224 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  225 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  226 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  227 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  228 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  229 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  230 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  231 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  232 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  233 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  234 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  235 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  236 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  237 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  238 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  239 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  240 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  241 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  242 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  243 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  244 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  245 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  246 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  247 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  248 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  249 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  250 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  251 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  252 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  253 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  254 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  255 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  256 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  257 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  258 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  259 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  260 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  261 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  262 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  263 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  264 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  265 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  266 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  267 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  268 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  269 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  270 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  271 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  272 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  273 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  274 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  275 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  276 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  277 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  278 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  279 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  280 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  281 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  282 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  283 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  284 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  285 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  286 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  287 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  288 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  289 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  290 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  291 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  292 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  293 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  294 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  295 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  296 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  297 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  298 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  299 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  300 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  301 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  302 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  303 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  304 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  305 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  306 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  307 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  308 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  309 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  310 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  311 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  312 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  313 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  314 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  315 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  316 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  317 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  318 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  319 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  320 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  321 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  322 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  323 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  324 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  325 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  326 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  327 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  328 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  329 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  330 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  331 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  332 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  333 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  334 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  335 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  336 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  337 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  338 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  339 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  340 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  341 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  342 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  343 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  344 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  345 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  346 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  347 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  348 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  349 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  350 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  351 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  352 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  353 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  354 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  355 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  356 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  357 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  358 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  359 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  360 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  361 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  362 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  363 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  364 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  365 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  366 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  367 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  368 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  369 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  370 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  371 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  372 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  373 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  374 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  375 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  376 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  377 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  378 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  379 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  380 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  381 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  382 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  383 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  384 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  385 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  386 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  387 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  388 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  389 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  390 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  391 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  392 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  393 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  394 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  395 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  396 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  397 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  398 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  399 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  400 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  401 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  402 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  403 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  404 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  405 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  406 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  407 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  408 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  409 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  410 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  411 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  412 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  413 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  414 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  415 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  416 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  417 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  418 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  419 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  420 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  421 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  422 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  423 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  424 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  425 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  426 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  427 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  428 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  429 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  430 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  431 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  432 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  433 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  434 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  435 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  436 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  437 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  438 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  439 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  440 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  441 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  442 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  443 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  444 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  445 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  446 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  447 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  448 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  449 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  450 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  451 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  452 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  453 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  454 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  455 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  456 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  457 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  458 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  459 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  460 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  461 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  462 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  463 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  464 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  465 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  466 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  467 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  468 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  469 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  470 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  471 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  472 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  473 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  474 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  475 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  476 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  477 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  478 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  479 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  480 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  481 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  482 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  483 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  484 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  485 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  486 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  487 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  488 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  489 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  490 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  491 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  492 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  493 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  494 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  495 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  496 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  497 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  498 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  499 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  500 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  501 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  502 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  503 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  504 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  505 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  506 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  507 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  508 / 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  509 / 510\n",
      "Done:  510 / 510\n"
     ]
    }
   ],
   "source": [
    "actual_analysis = test_dataset['Output']\n",
    "predicted_analysis = []\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for entry in test_dataset['Input']:\n",
    "    input_ids = tokenizer(entry, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=150,  # Generate more tokens for longer outputs\n",
    "        num_beams=5,         # Reduce beams to encourage more diversity\n",
    "        early_stopping=False, # Allow completion without stopping prematurely\n",
    "        repetition_penalty=3.0,  # Stronger penalty for repetition\n",
    "        length_penalty=1.0,   # Encourage longer and coherent outputs \n",
    "        temperature=0.9,      # Adjust temperature for more varied outputs   \n",
    "        top_k=50,             # Limit sampling to the top 50 words\n",
    "        top_p=0.95,           # Cumulative probability for token selection\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    predicted_analysis.append(decoded_output)\n",
    "    print(\"Done: \", len(predicted_analysis), \"/\", len(test_dataset['Input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:28<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 149.20 seconds, 3.42 sentences/sec\n",
      "BERT Score Precision: tensor(0.8427)\n",
      "BERT Score Recall: tensor(0.8622)\n",
      "BERT Score F1: tensor(0.8523)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(predicted_analysis, actual_analysis, lang='en', verbose=True)\n",
    "\n",
    "print(\"BERT Score Precision:\", P.mean())\n",
    "print(\"BERT Score Recall:\", R.mean())\n",
    "print(\"BERT Score F1:\", F1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_mean = P.mean()\n",
    "recall_mean = R.mean()\n",
    "f1_mean = F1.mean()\n",
    "\n",
    "labels = [\"Precision\", \"Recall\", \"F1\"]\n",
    "values = [precision_mean, recall_mean, f1_mean]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, values, color=[\"#91A195\", \"#D3A6A1\", \"#A1B0D3\"])\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"BERT Score Results\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.xlabel(\"Metrics\", fontsize=12)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", fontsize=10)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
